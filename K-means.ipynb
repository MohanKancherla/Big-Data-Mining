{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#author: Mohan Kancherla\n",
    "#CSCI 5702, Big Data Mining Assignment2\n",
    "\n",
    "#importing numpy, sparkcontext,distance and matlab plot\n",
    "import numpy as np\n",
    "from pyspark import SparkContext\n",
    "from scipy.spatial import distance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#opening spark session\n",
    "sc = SparkContext()\n",
    "# assigning default variables : iterations, datapath , centriod path and bool value\n",
    "Iterations = 20\n",
    "dataset_path = r\"C:\\Users\\mohan\\BigDataMining\\data.txt\"\n",
    "centroids_path = r\"C:\\Users\\mohan\\BigDataMining\\c1.txt\"\n",
    "euclidean_distance = True\n",
    "# Reading data to numpy array as float values\n",
    "data1= np.loadtxt(dataset_path,dtype=float)\n",
    "# Changing the data into RDD\n",
    "data_rdd = sc.parallelize(data1)\n",
    "data = data_rdd.map(lambda x : np.array(x.tolist()))\n",
    "# Reading centriods data into numpy array\n",
    "centroids_data = np.loadtxt(centroids_path)\n",
    "# definition of kmeans function with default parameters\n",
    "def kmeans(data,centroids, max_iterations, euclidean):\n",
    "    # assigning costs lists as empty lists \n",
    "    totalcost_euc=[]\n",
    "    totalcost_man=[]\n",
    "    # chether whether the bool passed is true or false\n",
    "    if(euclidean is True):\n",
    "        distType = \"Euclidean\"\n",
    "    else:\n",
    "        distType = \"Manhattan\"\n",
    "    # printing out iteration and distance type\n",
    "    print(\"Max Iterations : {}, distance measure : {}\".format(max_iterations, distType))\n",
    "    # looping through max iterations\n",
    "    for i in range(1, max_iterations+1):\n",
    "        # finding clusters using euclidean distance\n",
    "        if euclidean == True:\n",
    "            # finding distance for each data point with centriods\n",
    "            dist = data.map(lambda x: (x, np.array([distance.euclidean(x, z) for z in centroids])))\n",
    "            # mapping with lowest distance centriod index\n",
    "            dist2 = dist.map(lambda x: (np.argmin(x[1]),x[0]))\n",
    "            # group and sort by key value\n",
    "            dist3 = dist2.groupByKey().sortByKey().mapValues(list)\n",
    "            # finding cost incurred for the above iteration\n",
    "            Cost = data.map(lambda x: np.array([(distance.euclidean(x, z))**2 for z in centroids]))\n",
    "            Cost2 = Cost.map(lambda x: np.min(x))\n",
    "            #print(Cost2.collect())\n",
    "            # finding overallcost incurred with the mentioned formula in pdf\n",
    "            Cost3 = sum(Cost2.collect())\n",
    "            # printing out total cost values\n",
    "            print(\"Iteration {}: {}\".format(i, Cost3))\n",
    "            # appending into list\n",
    "            totalcost_euc.append(Cost3)\n",
    "            # calculating new centriods for the found clusters\n",
    "            new_centroids = dist3.map(lambda x: np.average(x[1], axis=0))\n",
    "        else:\n",
    "            # using manhattan distance, calculating the distance between centriod and each data point\n",
    "            dist = data.map(lambda x: (x, np.array([distance.cityblock(x, z) for z in centroids])))\n",
    "            dist2 = dist.map(lambda x: (np.argmin(x[1]),x[0]))\n",
    "            # minimum values are grouped and sorted by key values\n",
    "            dist3 = dist2.groupByKey().sortByKey().mapValues(list)\n",
    "            # finding the cost incuured using manhattan distance\n",
    "            Cost = data.map(lambda x: np.array([(distance.cityblock(x, z)) for z in centroids]))\n",
    "            Cost2 = Cost.map(lambda x: np.min(x))\n",
    "            # total cost incurred\n",
    "            totalcost = sum(Cost2.collect())\n",
    "            print(\"Iteration {}: {}\".format(i, totalcost))\n",
    "            totalcost_man.append(totalcost)\n",
    "            # calculating new centriods with the found clusters\n",
    "            new_centroids = dist3.map(lambda x: np.average(x[1], axis=0))\n",
    "            \n",
    "        # new centriods is passed to the for loop to recompute\n",
    "        centroids = np.array(new_centroids.collect())\n",
    "    # if we have euclidean values, it will plot the graph or else it will plot with manhattan distance\n",
    "    if(len(totalcost_euc)>0):\n",
    "        plt.plot([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20], totalcost_euc)\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Total cost using Eculidean distance')\n",
    "        plt.title('Iteration vs Total cost incurred')\n",
    "        plt.show()\n",
    "    elif(len(totalcost_man)>0):\n",
    "        plt.plot([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20], totalcost_man)\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Total cost using manhattan distance')\n",
    "        plt.title('Iteration vs Total cost incurred')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Graph is not plotted\")\n",
    "\n",
    "# calling the function with true value as euclidean distance\n",
    "kmeans(data,centroids_data, Iterations,euclidean_distance)\n",
    "# calling the kmeans function with false value as manhattan distance\n",
    "kmeans(data,centroids_data, Iterations,False)\n",
    "\n",
    "# finally closing the spark session\n",
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
